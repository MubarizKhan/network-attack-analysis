<!DOCTYPE html><html><head><meta charset="utf-8"><title>fyp</title></head><body><hr />
<p>Research Papers/ Literature Review:</p>
<p>1)  Attention Is All You Need:   <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a></p>
<p>2)  WELL-READ STUDENTS LEARN BETTER: ON THE IMPORTANCE OF PRE- 
     TRAINING COMPACT MODELS: 
     <a href="https://arxiv.org/pdf/1908.08962.pdf">https://arxiv.org/pdf/1908.08962.pdf</a></p>
<p>3)  Malware Detection on Highly Imbalanced Data through Sequence Modeling:
     <a href="https://dl.acm.org/doi/pdf/10.1145/3338501.3357374">https://dl.acm.org/doi/pdf/10.1145/3338501.3357374</a></p>
<p>4)  BERT: Pre-training of Deep Bidirectional Transformers for 
     Language Understanding:
     <a href="https://arxiv.org/pdf/1810.04805.pdf">https://arxiv.org/pdf/1810.04805.pdf</a></p>
<p>Articles / Blog Posts / GitHub Code:</p>
<p>1)  Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language 
     Processing:
     <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html</a></p>
<p>2)  <a href="https://jalammar.github.io/illustrated-bert/">https://jalammar.github.io/illustrated-bert/</a>
https:github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A<em>Visual</em>Notebook<em>to</em>Using<em>BERT</em>for<em>the</em>First_Time.ipynb
<a href="https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/">https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/</a></p>
<p>3)  BERT Word Embeddings Tutorial: 
     <a href="http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#contents">http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#contents</a></p>
<p>4)  Anti Social Online Behaviour Detection with BERT:
     https://humboldt- 
     wi.github.io/blog/research/information<em>systems</em>1920/bert<em>blog</em>post/</p>
<p>5)  Text classification with transformers in Tensorflow 2: BERT:
      <a href="https://medium.com/atheros/text-classification-with-transformers-in-tensorflow-2-">https://medium.com/atheros/text-classification-with-transformers-in-tensorflow-2-</a> 
      bert-2f4f16eff5ad</p>
<p>6)   google-research/bert:
      <a href="https://github.com/google-research/bert">https://github.com/google-research/bert</a></p>
<p>7)   <a href="https://huggingface.co/">https://huggingface.co/</a></p>
<hr /></body></html>